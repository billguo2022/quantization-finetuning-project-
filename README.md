# quantization-finetuning-project-

It's a small project on quantization and finetuning

This project demonstrates how to apply SmoothQuant quantization and QLoRA fine-tuning techniques to large language models like Llama 2 and opt. SmoothQuant helps reduce model size and computational overhead by quantizing weights and activations, making it feasible to handle large models with limited GPU memory. QLoRA then fine-tunes these compact models using LoRA adapters, which are small, efficient add-on weights. Together, these methods enable you to train and deploy powerful LLMs more affordably, without significant loss in performance.

detailed walk through is in the code
ignore the errors in the code output, the last run was experimental
